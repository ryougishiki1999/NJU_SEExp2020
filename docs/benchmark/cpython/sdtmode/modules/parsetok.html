<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta charset="utf-8"/>
        <title>Parser/parsetok.c</title>
        <link rel="stylesheet" type="text/css" href="../css/prettyprint.css"/>
        <script type="text/javascript" src="../js/prettyprint.js"></script>
    </head>
    <body onload="prettyPrint()">
		<pre class="prettyprint lang-cpp linenums">

/* Parser-tokenizer link implementation */

#include "Python.h"
#include "tokenizer.h"
#include "node.h"
#include "grammar.h"
#include "parser.h"
#include "parsetok.h"
#include "errcode.h"
#include "graminit.h"


/* Forward */
static node *parsetok(struct tok_state *, grammar *, int, perrdetail *, int *);
static int initerr(perrdetail *err_ret, PyObject * filename);

typedef struct {
    struct {
        int lineno;
        char *comment;
    } *items;
    size_t size;
    size_t num_items;
} growable_comment_array;

static int
growable_comment_array_init(growable_comment_array *arr, size_t initial_size) {
    assert(initial_size &gt; 0);
    arr-&gt;items = malloc(initial_size * sizeof(*arr-&gt;items));
    arr-&gt;size = initial_size;
    arr-&gt;num_items = 0;

    return arr-&gt;items != NULL;
}

static int
growable_comment_array_add(growable_comment_array *arr, int lineno, char *comment) {
    if (arr-&gt;num_items &gt;= arr-&gt;size) {
        arr-&gt;size *= 2;
        arr-&gt;items = realloc(arr-&gt;items, arr-&gt;size * sizeof(*arr-&gt;items));
        if (!arr-&gt;items) {
            return 0;
        }
    }

    arr-&gt;items[arr-&gt;num_items].lineno = lineno;
    arr-&gt;items[arr-&gt;num_items].comment = comment;
    arr-&gt;num_items++;
    return 1;
}

static void
growable_comment_array_deallocate(growable_comment_array *arr) {
    for (unsigned i = 0; i &lt; arr-&gt;num_items; i++) {
        PyObject_FREE(arr-&gt;items[i].comment);
    }
    free(arr-&gt;items);
}

/* Parse input coming from a string.  Return error code, print some errors. */
node *
PyParser_ParseString(const char *s, grammar *g, int start, perrdetail *err_ret)
{
    return PyParser_ParseStringFlagsFilename(s, NULL, g, start, err_ret, 0);
}

node *
PyParser_ParseStringFlags(const char *s, grammar *g, int start,
                          perrdetail *err_ret, int flags)
{
    return PyParser_ParseStringFlagsFilename(s, NULL,
                                             g, start, err_ret, flags);
}

node *
PyParser_ParseStringFlagsFilename(const char *s, const char *filename,
                          grammar *g, int start,
                          perrdetail *err_ret, int flags)
{
    int iflags = flags;
    return PyParser_ParseStringFlagsFilenameEx(s, filename, g, start,
                                               err_ret, &amp;iflags);
}

node *
PyParser_ParseStringObject(const char *s, PyObject *filename,
                           grammar *g, int start,
                           perrdetail *err_ret, int *flags)
{
    struct tok_state *tok;
    int exec_input = start == file_input;

    if (initerr(err_ret, filename) &lt; 0)
        return NULL;

    if (PySys_Audit("compile", "yO", s, err_ret-&gt;filename) &lt; 0) {
        err_ret-&gt;error = E_ERROR;
        return NULL;
    }

    if (*flags &amp; PyPARSE_IGNORE_COOKIE)
        tok = PyTokenizer_FromUTF8(s, exec_input);
    else
        tok = PyTokenizer_FromString(s, exec_input);
    if (tok == NULL) {
        err_ret-&gt;error = PyErr_Occurred() ? E_DECODE : E_NOMEM;
        return NULL;
    }
    if (*flags &amp; PyPARSE_TYPE_COMMENTS) {
        tok-&gt;type_comments = 1;
    }

    Py_INCREF(err_ret-&gt;filename);
    tok-&gt;filename = err_ret-&gt;filename;
    if (*flags &amp; PyPARSE_ASYNC_HACKS)
        tok-&gt;async_hacks = 1;
    return parsetok(tok, g, start, err_ret, flags);
}

node *
PyParser_ParseStringFlagsFilenameEx(const char *s, const char *filename_str,
                          grammar *g, int start,
                          perrdetail *err_ret, int *flags)
{
    node *n;
    PyObject *filename = NULL;
    if (filename_str != NULL) {
        filename = PyUnicode_DecodeFSDefault(filename_str);
        if (filename == NULL) {
            err_ret-&gt;error = E_ERROR;
            return NULL;
        }
    }
    n = PyParser_ParseStringObject(s, filename, g, start, err_ret, flags);
    Py_XDECREF(filename);
    return n;
}

/* Parse input coming from a file.  Return error code, print some errors. */

node *
PyParser_ParseFile(FILE *fp, const char *filename, grammar *g, int start,
                   const char *ps1, const char *ps2,
                   perrdetail *err_ret)
{
    return PyParser_ParseFileFlags(fp, filename, NULL,
                                   g, start, ps1, ps2, err_ret, 0);
}

node *
PyParser_ParseFileFlags(FILE *fp, const char *filename, const char *enc,
                        grammar *g, int start,
                        const char *ps1, const char *ps2,
                        perrdetail *err_ret, int flags)
{
    int iflags = flags;
    return PyParser_ParseFileFlagsEx(fp, filename, enc, g, start, ps1,
                                     ps2, err_ret, &amp;iflags);
}

node *
PyParser_ParseFileObject(FILE *fp, PyObject *filename,
                         const char *enc, grammar *g, int start,
                         const char *ps1, const char *ps2,
                         perrdetail *err_ret, int *flags)
{
    struct tok_state *tok;

    if (initerr(err_ret, filename) &lt; 0)
        return NULL;

    if (PySys_Audit("compile", "OO", Py_None, err_ret-&gt;filename) &lt; 0) {
        return NULL;
    }

    if ((tok = PyTokenizer_FromFile(fp, enc, ps1, ps2)) == NULL) {
        err_ret-&gt;error = E_NOMEM;
        return NULL;
    }
    if (*flags &amp; PyPARSE_TYPE_COMMENTS) {
        tok-&gt;type_comments = 1;
    }
    Py_INCREF(err_ret-&gt;filename);
    tok-&gt;filename = err_ret-&gt;filename;
    return parsetok(tok, g, start, err_ret, flags);
}

node *
PyParser_ParseFileFlagsEx(FILE *fp, const char *filename,
                          const char *enc, grammar *g, int start,
                          const char *ps1, const char *ps2,
                          perrdetail *err_ret, int *flags)
{
    node *n;
    PyObject *fileobj = NULL;
    if (filename != NULL) {
        fileobj = PyUnicode_DecodeFSDefault(filename);
        if (fileobj == NULL) {
            err_ret-&gt;error = E_ERROR;
            return NULL;
        }
    }
    n = PyParser_ParseFileObject(fp, fileobj, enc, g,
                                 start, ps1, ps2, err_ret, flags);
    Py_XDECREF(fileobj);
    return n;
}

#ifdef PY_PARSER_REQUIRES_FUTURE_KEYWORD
#if 0
static const char with_msg[] =
"%s:%d: Warning: 'with' will become a reserved keyword in Python 2.6\n";

static const char as_msg[] =
"%s:%d: Warning: 'as' will become a reserved keyword in Python 2.6\n";

static void
warn(const char *msg, const char *filename, int lineno)
{
    if (filename == NULL)
        filename = "&lt;string&gt;";
    PySys_WriteStderr(msg, filename, lineno);
}
#endif
#endif

/* Parse input coming from the given tokenizer structure.
   Return error code. */

static node *
parsetok(struct tok_state *tok, grammar *g, int start, perrdetail *err_ret,
         int *flags)
{
    parser_state *ps;
    node *n;
    int started = 0;
    int col_offset, end_col_offset;
    growable_comment_array type_ignores;

    if (!growable_comment_array_init(&amp;type_ignores, 10)) {
<span style = "background-color:#fdd">        err_ret-&gt;error = E_NOMEM;        Memory Leak:Potential memory leak at pointer 'type_ignores.items'</span>
        PyTokenizer_Free(tok);
        return NULL;
    }

    if ((ps = PyParser_New(g, start)) == NULL) {
<span style = "background-color:#fdd">        err_ret-&gt;error = E_NOMEM;        Memory Leak:Potential memory leak at pointer 'type_ignores.items'</span>
        PyTokenizer_Free(tok);
        return NULL;
    }
#ifdef PY_PARSER_REQUIRES_FUTURE_KEYWORD
    if (*flags &amp; PyPARSE_BARRY_AS_BDFL)
        ps-&gt;p_flags |= CO_FUTURE_BARRY_AS_BDFL;
    if (*flags &amp; PyPARSE_TYPE_COMMENTS)
        ps-&gt;p_flags |= PyCF_TYPE_COMMENTS;
#endif

    for (;;) {
        char *a, *b;
        int type;
        size_t len;
        char *str;
        col_offset = -1;
        int lineno;
        const char *line_start;

        type = PyTokenizer_Get(tok, &amp;a, &amp;b);
        if (type == ERRORTOKEN) {
            err_ret-&gt;error = tok-&gt;done;
            break;
        }
        if (type == ENDMARKER &amp;&amp; started) {
            type = NEWLINE; /* Add an extra newline */
            started = 0;
            /* Add the right number of dedent tokens,
               except if a certain flag is given --
               codeop.py uses this. */
            if (tok-&gt;indent &amp;&amp;
                !(*flags &amp; PyPARSE_DONT_IMPLY_DEDENT))
            {
                tok-&gt;pendin = -tok-&gt;indent;
                tok-&gt;indent = 0;
            }
        }
        else
            started = 1;
        len = (a != NULL &amp;&amp; b != NULL) ? b - a : 0;
        str = (char *) PyObject_MALLOC(len + 1);
        if (str == NULL) {
            err_ret-&gt;error = E_NOMEM;
            break;
        }
        if (len &gt; 0)
            strncpy(str, a, len);
        str[len] = '\0';

#ifdef PY_PARSER_REQUIRES_FUTURE_KEYWORD
        if (type == NOTEQUAL) {
            if (!(ps-&gt;p_flags &amp; CO_FUTURE_BARRY_AS_BDFL) &amp;&amp;
                            strcmp(str, "!=")) {
                PyObject_FREE(str);
                err_ret-&gt;error = E_SYNTAX;
                break;
            }
            else if ((ps-&gt;p_flags &amp; CO_FUTURE_BARRY_AS_BDFL) &amp;&amp;
                            strcmp(str, "&lt;&gt;")) {
                PyObject_FREE(str);
                err_ret-&gt;expected = NOTEQUAL;
                err_ret-&gt;error = E_SYNTAX;
                break;
            }
        }
#endif

        /* Nodes of type STRING, especially multi line strings
           must be handled differently in order to get both
           the starting line number and the column offset right.
           (cf. issue 16806) */
        lineno = type == STRING ? tok-&gt;first_lineno : tok-&gt;lineno;
        line_start = type == STRING ? tok-&gt;multi_line_start : tok-&gt;line_start;
        if (a != NULL &amp;&amp; a &gt;= line_start) {
            col_offset = Py_SAFE_DOWNCAST(a - line_start,
                                          intptr_t, int);
        }
        else {
            col_offset = -1;
        }

        if (b != NULL &amp;&amp; b &gt;= tok-&gt;line_start) {
            end_col_offset = Py_SAFE_DOWNCAST(b - tok-&gt;line_start,
                                              intptr_t, int);
        }
        else {
            end_col_offset = -1;
        }

        if (type == TYPE_IGNORE) {
            if (!growable_comment_array_add(&amp;type_ignores, tok-&gt;lineno, str)) {
                err_ret-&gt;error = E_NOMEM;
                break;
            }
            continue;
        }

        if ((err_ret-&gt;error =
             PyParser_AddToken(ps, (int)type, str,
                               lineno, col_offset, tok-&gt;lineno, end_col_offset,
                               &amp;(err_ret-&gt;expected))) != E_OK) {
            if (err_ret-&gt;error != E_DONE) {
                PyObject_FREE(str);
                err_ret-&gt;token = type;
            }
            break;
        }
    }

    if (err_ret-&gt;error == E_DONE) {
        n = ps-&gt;p_tree;
        ps-&gt;p_tree = NULL;

        if (n-&gt;n_type == file_input) {
            /* Put type_ignore nodes in the ENDMARKER of file_input. */
            int num;
            node *ch;
            size_t i;

            num = NCH(n);
            ch = CHILD(n, num - 1);
            REQ(ch, ENDMARKER);

            for (i = 0; i &lt; type_ignores.num_items; i++) {
                int res = PyNode_AddChild(ch, TYPE_IGNORE, type_ignores.items[i].comment,
                                          type_ignores.items[i].lineno, 0,
                                          type_ignores.items[i].lineno, 0);
                if (res != 0) {
                    err_ret-&gt;error = res;
                    PyNode_Free(n);
                    n = NULL;
                    break;
                }
                type_ignores.items[i].comment = NULL;
            }
        }

        /* Check that the source for a single input statement really
           is a single statement by looking at what is left in the
           buffer after parsing.  Trailing whitespace and comments
           are OK.  */
        if (err_ret-&gt;error == E_DONE &amp;&amp; start == single_input) {
            char *cur = tok-&gt;cur;
            char c = *tok-&gt;cur;

            for (;;) {
                while (c == ' ' || c == '\t' || c == '\n' || c == '\014')
                    c = *++cur;

                if (!c)
                    break;

                if (c != '#') {
                    err_ret-&gt;error = E_BADSINGLE;
                    PyNode_Free(n);
                    n = NULL;
                    break;
                }

                /* Suck up comment. */
                while (c &amp;&amp; c != '\n')
                    c = *++cur;
            }
        }
    }
    else
        n = NULL;

    growable_comment_array_deallocate(&amp;type_ignores);

#ifdef PY_PARSER_REQUIRES_FUTURE_KEYWORD
    *flags = ps-&gt;p_flags;
#endif
    PyParser_Delete(ps);

    if (n == NULL) {
        if (tok-&gt;done == E_EOF)
            err_ret-&gt;error = E_EOF;
        err_ret-&gt;lineno = tok-&gt;lineno;
        if (tok-&gt;buf != NULL) {
            size_t len;
            assert(tok-&gt;cur - tok-&gt;buf &lt; INT_MAX);
            /* if we've managed to parse a token, point the offset to its start,
             * else use the current reading position of the tokenizer
             */
            err_ret-&gt;offset = col_offset != -1 ? col_offset + 1 : ((int)(tok-&gt;cur - tok-&gt;buf));
            len = tok-&gt;inp - tok-&gt;buf;
            err_ret-&gt;text = (char *) PyObject_MALLOC(len + 1);
            if (err_ret-&gt;text != NULL) {
                if (len &gt; 0)
                    strncpy(err_ret-&gt;text, tok-&gt;buf, len);
                err_ret-&gt;text[len] = '\0';
            }
        }
    } else if (tok-&gt;encoding != NULL) {
        /* 'nodes-&gt;n_str' uses PyObject_*, while 'tok-&gt;encoding' was
         * allocated using PyMem_
         */
        node* r = PyNode_New(encoding_decl);
        if (r)
            r-&gt;n_str = PyObject_MALLOC(strlen(tok-&gt;encoding)+1);
        if (!r || !r-&gt;n_str) {
            err_ret-&gt;error = E_NOMEM;
            if (r)
                PyObject_FREE(r);
            n = NULL;
            goto done;
        }
        strcpy(r-&gt;n_str, tok-&gt;encoding);
        PyMem_FREE(tok-&gt;encoding);
        tok-&gt;encoding = NULL;
        r-&gt;n_nchildren = 1;
        r-&gt;n_child = n;
        n = r;
    }

done:
    PyTokenizer_Free(tok);

    if (n != NULL) {
        _PyNode_FinalizeEndPos(n);
    }
    return n;
}

static int
initerr(perrdetail *err_ret, PyObject *filename)
{
    err_ret-&gt;error = E_OK;
    err_ret-&gt;lineno = 0;
    err_ret-&gt;offset = 0;
    err_ret-&gt;text = NULL;
    err_ret-&gt;token = -1;
    err_ret-&gt;expected = -1;
    if (filename) {
        Py_INCREF(filename);
        err_ret-&gt;filename = filename;
    }
    else {
        err_ret-&gt;filename = PyUnicode_FromString("&lt;string&gt;");
        if (err_ret-&gt;filename == NULL) {
            err_ret-&gt;error = E_ERROR;
            return -1;
        }
    }
    return 0;
}
      </pre>
    </body>
</html>
